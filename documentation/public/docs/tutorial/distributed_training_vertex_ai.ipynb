{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training with VertexAI\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/yggdrasil-decision-forests/blob/main/documentation/public/docs/tutorial/distributed_training_vertex_ai.ipynb)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ydf -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:1px solid #AF8FDF; background-color:#EADCFF; padding: 5px;\">\n",
    "<p>For a general introduction to distributed training with YDF, see the <a href=\"https://ydf.readthedocs.io/en/latest/tutorial/distributed_training/\">YDF Distributed Training</a> tutorial.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:1px solid #8FAFDF; background-color:#DCEAFF; padding: 5px;\">\n",
    "<b>For Googlers</b>\n",
    "<p>YDF internal examples available at <a href=\"http://go/ydf/examples\">go/ydf/examples</a> demonstrate how to use distributed training on Google infrastructure.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "By default YDF trains a model using a single computer. This works well for datasets with less than a few millions examples, but this does not work for datasets with billions of examples. YDF distributed training solves this problem by dividing the computation over multiple machines. As a rule of thumb, start distributed training once the dataset size exceeds 100M examples.\n",
    "\n",
    "[Vertex AI](https://cloud.google.com/vertex-ai) is a service of [Google Cloud](https://en.wikipedia.org/wiki/Google_Cloud_Platform) to train ML models (and other things) on many computers. This tutorial shows how to train a YDF model without and with distributed training with Vertex AI.\n",
    "\n",
    " If you are unfamiliar with YDF, make sure to read the [Getting Started](../getting_started) tutorial first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login and setup Google Cloud and Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use the [gcloud CLI](https://cloud.google.com/sdk/docs/install). Make sure it is installed.\n",
    "\n",
    "The commands from this tutorial can be typed in a shell or in a colab cell (with the `!` or `%%bash` prefix).\n",
    "\n",
    "Note that the `gcloud auth login` command does not always work in Jupyter Notebooks. In this case, typing it in a shell is better.\n",
    "\n",
    "The first step is to login and set our project. In a shell, use the command:\n",
    "\n",
    "```shell\n",
    "gcloud auth login\n",
    "gcloud config set project <PROJECT_ID>\n",
    "```\n",
    "\n",
    "In a Google Colab, you can do the following instead:\n",
    "\n",
    "```python\n",
    "from google.colab import auth\n",
    "auth.authenticate_user(project_id=PROJECT_ID)\n",
    "```\n",
    "\n",
    "In this example, we use the project id is `custom-oasis-452410-c2`, but to run this example you need to create your own project.\n",
    "\n",
    "Next we need to enable two cloud services: VertexAI (previously known as AI Platform) and Cloud Build (to build the dockers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable cloudbuild.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Cloud automatically creates a \"service account\" named <Project number>-compute@developer.gserviceaccount.com. For example, in this example, my service account is `282665763673-compute@developer.gserviceaccount.com`. You can find it in the Google Cloud console or my typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282665763673\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects describe custom-oasis-452410-c2 --format=\"value(projectNumber)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The project ID and project number are two different identifiers.\n",
    "\n",
    "The service account will be responsible for the docker packing and running the job. For this, you need to give it those permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud projects add-iam-policy-binding custom-oasis-452410-c2 \\\n",
    "    --member=\"serviceAccount:282665763673-compute@developer.gserviceaccount.com\" \\\n",
    "    --role=\"roles/storage.objectViewer\"\n",
    "\n",
    "gcloud projects add-iam-policy-binding custom-oasis-452410-c2 \\\n",
    "    --member=\"serviceAccount:282665763673-compute@developer.gserviceaccount.com\" \\\n",
    "    --role=\"roles/run.builder\"\n",
    "\n",
    "gcloud projects add-iam-policy-binding custom-oasis-452410-c2 \\\n",
    "    --member=\"serviceAccount:282665763673-compute@developer.gserviceaccount.com\" \\\n",
    "    --role=\"roles/artifactregistry.createOnPushWriter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that Google Cloud is configured, we can configure the model :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "First we need a dataset. A good option is to use CSV, Avro or TensorFlowRecord files in a [bucket](https://cloud.google.com/storage/docs/creating-buckets). We will use CSV in this example.\n",
    "\n",
    "For the training to be efficient, the dataset needs to be divided into several files (also known as \"sharding\"). In this section, we download the \"adult\" dataset, divide it into pieces, and save them in a bucket.\n",
    "\n",
    "Ideally, the number of shards should be ~10x the number of workers. So if you train with 20 workers, splitting the data into 200 pieces is a good idea. \n",
    "\n",
    "The adult dataset is a small dataset with only ~30k examples. It does not need distributed training, but it is good for the demonstration.\n",
    "\n",
    "First, let's create a Bucket where we will store the dataset, model, and temporary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://ydf_bucket/...\n"
     ]
    }
   ],
   "source": [
    "!gcloud storage buckets create gs://ydf_bucket --location=us-east1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's download a dataset.\n",
    "\n",
    "**Note:** For a real large dataset, you will likely export the data using [Google Bigtable](https://cloud.google.com/bigtable) or generate it with [Apache Beam](https://beam.apache.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 22792 training examples\n"
     ]
    }
   ],
   "source": [
    "ds_path = \"https://raw.githubusercontent.com/google/yggdrasil-decision-forests/main/yggdrasil_decision_forests/test_data/dataset\"\n",
    "train_ds = pd.read_csv(f\"{ds_path}/adult_train.csv\")\n",
    "test_ds = pd.read_csv(f\"{ds_path}/adult_test.csv\")\n",
    "\n",
    "print(\"The dataset has\",len(train_ds),\"training examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the dataset and upload it to our bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://ydf_bucket/train_dataset/shard_0.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_1.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_2.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_3.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_4.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_5.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_6.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_7.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_8.csv',\n",
       " 'gs://ydf_bucket/train_dataset/shard_9.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_dataset(\n",
    "    dataset: pd.DataFrame, tmp_dir: str, num_shards: int\n",
    ") -> list[str]:\n",
    "  \"\"\"Splits a csv file into multiple csv files.\"\"\"\n",
    "\n",
    "  os.makedirs(tmp_dir,exist_ok=True)\n",
    "  num_row_per_shard = (dataset.shape[0] + num_shards - 1) // num_shards\n",
    "  paths = []\n",
    "  for shard_idx in range(num_shards):\n",
    "    begin_idx = shard_idx * num_row_per_shard\n",
    "    end_idx = (shard_idx + 1) * num_row_per_shard\n",
    "    shard_dataset = dataset.iloc[begin_idx:end_idx]\n",
    "    shard_path = os.path.join(tmp_dir , f\"shard_{shard_idx}.csv\")\n",
    "    paths.append(shard_path)\n",
    "    shard_dataset.to_csv(shard_path, index=False)\n",
    "  return paths\n",
    "\n",
    "split_dataset(train_ds, \"gs://ydf_bucket/train_dataset\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `gcloud storage ls` command, we can make sure the dataset is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ydf_bucket/train_dataset/shard_0.csv\n",
      "gs://ydf_bucket/train_dataset/shard_1.csv\n",
      "gs://ydf_bucket/train_dataset/shard_2.csv\n",
      "gs://ydf_bucket/train_dataset/shard_3.csv\n",
      "gs://ydf_bucket/train_dataset/shard_4.csv\n",
      "gs://ydf_bucket/train_dataset/shard_5.csv\n",
      "gs://ydf_bucket/train_dataset/shard_6.csv\n",
      "gs://ydf_bucket/train_dataset/shard_7.csv\n",
      "gs://ydf_bucket/train_dataset/shard_8.csv\n",
      "gs://ydf_bucket/train_dataset/shard_9.csv\n"
     ]
    }
   ],
   "source": [
    "!gcloud storage ls gs://ydf_bucket/train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also save the testing dataset.\n",
    "\n",
    "We will use it for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://ydf_bucket/valid_dataset/shard_0.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_1.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_2.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_3.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_4.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_5.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_6.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_7.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_8.csv',\n",
       " 'gs://ydf_bucket/valid_dataset/shard_9.csv']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset(test_ds, \"gs://ydf_bucket/valid_dataset\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create docker\n",
    "\n",
    "To run in VectexAI, the code cannot be executed in a notebook. Instead, the training code needs to be packaged in a Docker.\n",
    "\n",
    "To pass the dataset path and other options to the training program, we use the `argparse` library. We also add an option to enable or disable distributed training. This will be useful to test the trainer quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "import argparse\n",
    "import dataclasses\n",
    "import json\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n",
    "import ydf\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# Path to training dataset. Should be prefixed with the dataset type e.g. 'csv':.\n",
    "# See the supported formats at https://ydf.readthedocs.io/en/latest/dataset_formats/\n",
    "parser.add_argument(\"--train_ds\", type=str, required=True)\n",
    "# Path to validation dataset. If empty, the model is trained without validation.\n",
    "parser.add_argument(\"--valid_ds\", type=str)\n",
    "# Path to test dataset. If empty, the model is not evaluated.\n",
    "parser.add_argument(\"--test_ds\", type=str)\n",
    "# Path to save the model.\n",
    "parser.add_argument(\"--model\", type=str, required=True)\n",
    "# Work directory containing the temporary working data. Only used for distributed training.\n",
    "parser.add_argument(\"--work_dir\", default=\"\", type=str)\n",
    "# Label column to predict.\n",
    "parser.add_argument(\"--label\", type=str, required=True)\n",
    "# Is the training distributed, or on a single machine?\n",
    "parser.add_argument(\"--distributed\", action=\"store_true\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "  print(\"Arguments:\\n\", args)\n",
    "\n",
    "  if args.distributed:\n",
    "    main_distributed()\n",
    "  else:\n",
    "    main_in_process()\n",
    "\n",
    "\n",
    "def main_in_process():\n",
    "  ydf.verbose(2)\n",
    "\n",
    "  print(\"Train model in process on\", args.train_ds)\n",
    "  learner = ydf.GradientBoostedTreesLearner(label=args.label)\n",
    "  model = learner.train(args.train_ds, valid=args.valid_ds)\n",
    "\n",
    "  print(\"Save model in\", args.model)\n",
    "  model.save(args.model)\n",
    "\n",
    "  if args.test_ds:\n",
    "    print(\"Evaluate model on\", args.test_ds)\n",
    "    evaluation = model.evaluate(args.test_ds)\n",
    "    print(evaluation)\n",
    "\n",
    "\n",
    "def main_distributed():\n",
    "  ydf.verbose(2)\n",
    "\n",
    "  # Gather the manager and workers configuration.\n",
    "  cluster_config = ydf.util.get_vertex_ai_cluster_spec()\n",
    "  print(\"cluster_config:\\n\", cluster_config)\n",
    "\n",
    "  if cluster_config.is_worker:\n",
    "    # This machine is running a worker.\n",
    "    ydf.start_worker(cluster_config.port)\n",
    "    return\n",
    "\n",
    "  print(\"Train model with distribution on\", args.train_ds)\n",
    "  learner = ydf.DistributedGradientBoostedTreesLearner(\n",
    "      label=args.label,\n",
    "      workers=cluster_config.workers,\n",
    "      working_dir=args.work_dir,\n",
    "      resume_training=True,\n",
    "  )\n",
    "  model = learner.train(args.train_ds, valid=args.valid_ds)\n",
    "\n",
    "  print(\"Save model in\", args.model)\n",
    "  model.save(args.model)\n",
    "\n",
    "  if args.test_ds:\n",
    "    print(\"Evaluate model on\", args.test_ds)\n",
    "    evaluation = model.evaluate(args.test_ds)\n",
    "    print(evaluation)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting a job on VertexAI takes a few minutes. Instead, to iterate quickly, it is a good idea to run the training script locally on a subset of the data.\n",
    "\n",
    "The following command runs our trainer locally without distributed training.\n",
    "\n",
    "**Note:** In YDF, the dataset paths always define the format of the dataset with a prefix (`csv:` in this example). To use another format, change the prefix accordingly. [Here](https://ydf.readthedocs.io/en/latest/dataset_formats/) is the list of supported formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python train.py --train_ds=csv:gs://ydf_bucket/train_dataset/shard_0.csv \\\n",
    "--valid_ds=csv:gs://ydf_bucket/valid_dataset/shard_0.csv \\\n",
    "--model=gs://ydf_bucket/model \\\n",
    "--label=income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be run in VertexAI, the trainer needs to be packaged in Docker. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.12\n",
    "WORKDIR /root\n",
    "\n",
    "RUN apt-get update && apt-get -y install sudo\n",
    "\n",
    "RUN rm -rf /usr/share/keyrings/cloud.google.gpg\n",
    "RUN rm -rf /etc/apt/sources.list.d/google-cloud-sdk.list\n",
    "RUN curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "RUN echo \"deb https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n",
    "\n",
    "# Install YDF from Pip\n",
    "RUN python3 -m pip install ydf\n",
    "# OR, install your own copy of YDF.\n",
    "# COPY ydf-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl .\n",
    "# RUN python3 -m pip install ydf-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --upgrade --no-cache-dir --force-reinstall\n",
    "\n",
    "RUN echo '[GoogleCompute]\\nservice_account = default' > /etc/boto.cfg\n",
    "\n",
    "COPY train.py /root/train.py\n",
    "\n",
    "ENTRYPOINT [\"python3\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compile the docker and upload it to Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud builds submit --tag gcr.io/custom-oasis-452410-c2/train-ydf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start a custom Vertex AI training job with our docker.\n",
    "\n",
    "A few remarks:\n",
    "\n",
    "You need to create two worker pools. The first worker pool contains the \"manager\" and will do very little computation. The second worker pool contains the machines that will train and evaluate the model. When training on a larger dataset, you need to increase the number of machines with the `replica-count` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/282665763673/locations/us-east1/customJobs/7048111014285410304] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "ud ai custom-jobs describe projects/282665763673/locations/us-east1/customJobs/7048111014285410304\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "65763673/locations/us-east1/customJobs/7048111014285410304\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai custom-jobs create \\\n",
    "    --region=us-east1 \\\n",
    "    --project=custom-oasis-452410-c2 \\\n",
    "    --worker-pool-spec=replica-count=1,machine-type='n1-highmem-2',container-image-uri='gcr.io/custom-oasis-452410-c2/train-ydf' \\\n",
    "    --worker-pool-spec=replica-count=5,machine-type='n1-highmem-2',container-image-uri='gcr.io/custom-oasis-452410-c2/train-ydf' \\\n",
    "    --display-name=train-ydf-job \\\n",
    "--args=\\\n",
    "--train_ds=csv:gs://ydf_bucket/train_dataset/shard_*.csv,\\\n",
    "--valid_ds=csv:gs://ydf_bucket/valid_dataset/shard_*.csv,\\\n",
    "--model=gs://ydf_bucket/model,\\\n",
    "--work_dir=gs://ydf_bucket/work_dir,\\\n",
    "--distributed,\\\n",
    "--label=income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the training in the [Vertex AI Custom Job console](https://pantheon.corp.google.com/vertex-ai/training/custom-jobs), or in your shell by running the printed command e.g.:\n",
    "\n",
    "```shell\n",
    "!gcloud ai custom-jobs stream-logs projects/282665763673/locations/us-east1/customJobs/8426212500260782080\n",
    "```\n",
    "**Note:** This command does not stop when the training is done. You need to stop it manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and test the model\n",
    "\n",
    "Now that your training is done, you can look at the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ydf.load_model(\"gs://ydf_bucket/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       ".tab_block .header {\n",
       "    flex-direction: row;\n",
       "    display: flex;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab {\n",
       "    cursor: pointer;\n",
       "    background-color: #F6F5F5;\n",
       "    text-decoration: none;\n",
       "    text-align: center;\n",
       "    padding: 4px 12px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab.selected {\n",
       "    border-bottom: 2px solid #2F80ED;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab:hover {\n",
       "    text-decoration: none;\n",
       "    background-color: #DCDCDC;\n",
       "}\n",
       "\n",
       ".tab_block .body .tab_content {\n",
       "    display: none;\n",
       "    padding: 5px;\n",
       "}\n",
       "\n",
       ".tab_block .body .tab_content.selected {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".ydf_pre {\n",
       "    font-size: medium;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       ".variable_importance {\n",
       "}\n",
       "\n",
       ".variable_importance select {\n",
       "}\n",
       "\n",
       ".variable_importance .content {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".variable_importance .content.selected {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table {\n",
       "  border-collapse: collapse;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table th {\n",
       "  background-color: #ededed;\n",
       "  font-weight: bold;\n",
       "  text-align: left;\n",
       "  padding: 3px 4px;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table td {\n",
       "  text-align: right;\n",
       "  padding: 3px 4px;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table .best {\n",
       "  background-color: khaki;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "\n",
       "function ydfShowTab(block_id, item) {\n",
       "    const block = document.getElementById(block_id);\n",
       "    \n",
       "    \n",
       "    console.log(\"HIDE first of:\",block.getElementsByClassName(\"tab selected\"));\n",
       "    console.log(\"HIDE first of:\",block.getElementsByClassName(\"tab_content selected\"));\n",
       "    \n",
       "    block.getElementsByClassName(\"tab selected\")[0].classList.remove(\"selected\");\n",
       "    block.getElementsByClassName(\"tab_content selected\")[0].classList.remove(\"selected\");\n",
       "    document.getElementById(block_id + \"_\" + item).classList.add(\"selected\");\n",
       "    document.getElementById(block_id + \"_body_\" + item).classList.add(\"selected\");\n",
       "}\n",
       "  \n",
       "\n",
       "function ydfShowVariableImportance(block_id) {\n",
       "    const block = document.getElementById(block_id);\n",
       "    const item = block.getElementsByTagName(\"select\")[0].value;\n",
       "    block.getElementsByClassName(\"content selected\")[0].classList.remove(\"selected\");\n",
       "    document.getElementById(block_id + \"_body_\" + item).classList.add(\"selected\");\n",
       "}\n",
       "\n",
       "</script>\n",
       "  <div class=\"tab_block\" id=\"5de0-c876-a9e4-7936\"><div class=\"header\"><a id=\"5de0-c876-a9e4-7936_model\" class=\"tab selected\" onclick=\"ydfShowTab('5de0-c876-a9e4-7936', 'model')\">Model</a><a id=\"5de0-c876-a9e4-7936_dataspec\" class=\"tab\" onclick=\"ydfShowTab('5de0-c876-a9e4-7936', 'dataspec')\">Dataspec</a><a id=\"5de0-c876-a9e4-7936_training\" class=\"tab\" onclick=\"ydfShowTab('5de0-c876-a9e4-7936', 'training')\">Training</a><a id=\"5de0-c876-a9e4-7936_variable_importance\" class=\"tab\" onclick=\"ydfShowTab('5de0-c876-a9e4-7936', 'variable_importance')\">Variable importances</a><a id=\"5de0-c876-a9e4-7936_structure\" class=\"tab\" onclick=\"ydfShowTab('5de0-c876-a9e4-7936', 'structure')\">Structure</a></div><div class=\"body\"><div id=\"5de0-c876-a9e4-7936_body_model\" class=\"tab_content selected\"><b>Name</b> : GRADIENT_BOOSTED_TREES<br><b>Task</b> : CLASSIFICATION<br><b>Label</b> : income<br><b>Features (14)</b> : age workclass fnlwgt education education_num marital_status occupation relationship race sex capital_gain capital_loss hours_per_week native_country<br><b>Weights</b> : None<br><b>Trained with tuner</b> : No<br><b>Model size</b> : 833 kB<br></div><div id=\"5de0-c876-a9e4-7936_body_dataspec\" class=\"tab_content\"><pre class=\"ydf_pre\">Number of records: 2280\n",
       "Number of columns: 15\n",
       "\n",
       "Number of columns by type:\n",
       "\tCATEGORICAL: 9 (60%)\n",
       "\tNUMERICAL: 6 (40%)\n",
       "\n",
       "Columns:\n",
       "\n",
       "CATEGORICAL: 9 (60%)\n",
       "\t1: &quot;workclass&quot; CATEGORICAL num-nas:123 (5.39474%) has-dict vocab-size:7 num-oods:2 (0.0927214%) most-frequent:&quot;Private&quot; 1586 (73.528%)\n",
       "\t3: &quot;education&quot; CATEGORICAL has-dict vocab-size:17 zero-ood-items most-frequent:&quot;HS-grad&quot; 764 (33.5088%)\n",
       "\t5: &quot;marital_status&quot; CATEGORICAL has-dict vocab-size:7 num-oods:3 (0.131579%) most-frequent:&quot;Married-civ-spouse&quot; 1052 (46.1404%)\n",
       "\t6: &quot;occupation&quot; CATEGORICAL num-nas:123 (5.39474%) has-dict vocab-size:14 zero-ood-items most-frequent:&quot;Craft-repair&quot; 323 (14.9745%)\n",
       "\t7: &quot;relationship&quot; CATEGORICAL has-dict vocab-size:7 zero-ood-items most-frequent:&quot;Husband&quot; 935 (41.0088%)\n",
       "\t8: &quot;race&quot; CATEGORICAL has-dict vocab-size:6 zero-ood-items most-frequent:&quot;White&quot; 1968 (86.3158%)\n",
       "\t9: &quot;sex&quot; CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:&quot;Male&quot; 1543 (67.6754%)\n",
       "\t13: &quot;native_country&quot; CATEGORICAL num-nas:39 (1.71053%) has-dict vocab-size:17 num-oods:49 (2.18652%) most-frequent:&quot;United-States&quot; 2043 (91.1647%)\n",
       "\t14: &quot;income&quot; CATEGORICAL manually-defined has-dict vocab-size:3 zero-ood-items most-frequent:&quot;&lt;=50K&quot; 1731 (75.9211%)\n",
       "\n",
       "NUMERICAL: 6 (40%)\n",
       "\t0: &quot;age&quot; NUMERICAL mean:39.0351 min:17 max:90 sd:13.7531\n",
       "\t2: &quot;fnlwgt&quot; NUMERICAL mean:190565 min:19914 max:1.22658e+06 sd:106876\n",
       "\t4: &quot;education_num&quot; NUMERICAL mean:10.0732 min:1 max:16 sd:2.55387\n",
       "\t10: &quot;capital_gain&quot; NUMERICAL mean:1054 min:0 max:99999 sd:7620.32\n",
       "\t11: &quot;capital_loss&quot; NUMERICAL mean:79.7206 min:0 max:3683 sd:387.973\n",
       "\t12: &quot;hours_per_week&quot; NUMERICAL mean:40.5614 min:1 max:99 sd:12.3992\n",
       "\n",
       "Terminology:\n",
       "\tnas: Number of non-available (i.e. missing) values.\n",
       "\tood: Out of dictionary.\n",
       "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
       "\ttokenized: The attribute value is obtained through tokenization.\n",
       "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
       "\tvocab-size: Number of unique values.\n",
       "</pre></div><div id=\"5de0-c876-a9e4-7936_body_training\" class=\"tab_content\"><p>The following evaluation is computed on the validation or out-of-bag dataset.</p><pre class=\"ydf_pre\">Task: CLASSIFICATION\n",
       "Label: income\n",
       "Loss (BINOMIAL_LOG_LIKELIHOOD): 0.643922\n",
       "\n",
       "Accuracy: 0.860798  CI95[W][0 1]\n",
       "ErrorRate: : 0.139202\n",
       "\n",
       "\n",
       "Confusion Table:\n",
       "truth\\prediction\n",
       "       &lt;=50K  &gt;50K\n",
       "&lt;=50K    678    49\n",
       " &gt;50K     87   163\n",
       "Total: 977\n",
       "\n",
       "</pre><div style='display: grid; gap: 0px; grid-auto-columns: min-content;'><div style='grid-row:1 / span 1; grid-column:1 / span 1;'><script src='https://www.gstatic.com/external_hosted/plotly/plotly.min.js'></script>\n",
       "<div id=\"chart_5de0_c876_a9e4_7936self_eval_item0\" style=\"display: inline-block;\" ></div>\n",
       "<script>\n",
       "  Plotly.newPlot(\n",
       "    'chart_5de0_c876_a9e4_7936self_eval_item0',\n",
       "    [{\n",
       "x: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108],\n",
       "y: [1.01646,0.951394,0.899609,0.854223,0.817364,0.785616,0.757206,0.73207,0.712114,0.689684,0.671869,0.656677,0.641031,0.628246,0.615952,0.604984,0.594316,0.586139,0.578078,0.570248,0.562973,0.555354,0.549517,0.541885,0.535967,0.529711,0.525877,0.517914,0.511165,0.507107,0.503578,0.497112,0.49253,0.487698,0.485214,0.480342,0.476534,0.473658,0.470822,0.46713,0.461464,0.457788,0.456225,0.451363,0.445864,0.442715,0.441333,0.437659,0.434115,0.432224,0.428903,0.425824,0.423411,0.420974,0.419117,0.41729,0.414458,0.412839,0.411007,0.406116,0.403152,0.401766,0.399074,0.39732,0.394745,0.392975,0.391751,0.389711,0.386732,0.381651,0.377744,0.374571,0.373533,0.371958,0.370396,0.369067,0.36817,0.36669,0.365511,0.361263,0.359271,0.358444,0.357682,0.356435,0.352667,0.348788,0.348095,0.34609,0.343412,0.340843,0.338305,0.33763,0.334894,0.334314,0.331465,0.330209,0.326852,0.326307,0.325146,0.324184,0.322898,0.321709,0.321185,0.319687,0.317282,0.316349,0.313048,0.312144],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "name: 'training',\n",
       "},\n",
       "{\n",
       "x: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108],\n",
       "y: [1.05087,0.987038,0.938152,0.897377,0.863547,0.835676,0.811813,0.791615,0.774608,0.758959,0.747233,0.737275,0.731242,0.721926,0.7148,0.705607,0.70141,0.696832,0.692523,0.687669,0.684373,0.681816,0.67919,0.674324,0.671071,0.66784,0.663906,0.663511,0.661772,0.658471,0.656894,0.655933,0.653565,0.652204,0.648937,0.647815,0.647662,0.647803,0.646514,0.648153,0.648486,0.648819,0.647348,0.648289,0.649545,0.650695,0.649634,0.648905,0.649616,0.647117,0.647255,0.648547,0.647968,0.648477,0.646126,0.645999,0.645992,0.644409,0.645055,0.645659,0.647137,0.645232,0.645851,0.645204,0.647201,0.64741,0.64624,0.646134,0.646858,0.646017,0.64611,0.646053,0.644487,0.644785,0.644377,0.64546,0.643925,0.643922,0.644839,0.645483,0.646237,0.645275,0.645986,0.646167,0.647801,0.650195,0.649322,0.649811,0.649588,0.650896,0.650952,0.650181,0.652867,0.653736,0.65456,0.655131,0.654738,0.653607,0.653823,0.653176,0.653246,0.653893,0.653141,0.653705,0.654765,0.654997,0.655862,0.656274],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "name: 'validation',\n",
       "},\n",
       "],\n",
       "    {\n",
       "      width: 600,\n",
       "      height: 400,\n",
       "      title: '',\n",
       "      showlegend: true,\n",
       "      xaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'iteration',\n",
       "        },\n",
       "      font: {\n",
       "        size: 10,\n",
       "        },\n",
       "      yaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'loss',\n",
       "        },\n",
       "      margin: {\n",
       "        l: 50,\n",
       "        r: 50,\n",
       "        b: 50,\n",
       "        t: 50,\n",
       "      },\n",
       "    },\n",
       "    {\n",
       "      modeBarButtonsToRemove: ['sendDataToCloud'],\n",
       "      displaylogo: false,displayModeBar: false,\n",
       "    }\n",
       "  );\n",
       "</script>\n",
       "</div><div style='grid-row:2 / span 1; grid-column:1 / span 1;'>\n",
       "<div id=\"chart_5de0_c876_a9e4_7936self_eval_item1\" style=\"display: inline-block;\" ></div>\n",
       "<script>\n",
       "  Plotly.newPlot(\n",
       "    'chart_5de0_c876_a9e4_7936self_eval_item1',\n",
       "    [{\n",
       "x: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108],\n",
       "y: [0.759211,0.759211,0.759211,0.770614,0.812281,0.855263,0.860965,0.864035,0.865789,0.869298,0.870614,0.87193,0.875439,0.874561,0.875877,0.876316,0.878509,0.879825,0.879825,0.882018,0.883333,0.885088,0.885088,0.886404,0.887281,0.889035,0.889474,0.890351,0.893421,0.89386,0.895175,0.896491,0.89693,0.899561,0.899561,0.900439,0.90307,0.903509,0.903947,0.905263,0.906579,0.908772,0.908772,0.910088,0.909211,0.910526,0.910965,0.912719,0.914035,0.914912,0.916667,0.917982,0.918421,0.91886,0.919298,0.919298,0.921053,0.922368,0.922368,0.924561,0.922807,0.922807,0.923684,0.924561,0.925439,0.926316,0.925877,0.926754,0.929386,0.930263,0.932456,0.934211,0.933772,0.934649,0.935088,0.935526,0.935526,0.935088,0.934649,0.935526,0.935965,0.935965,0.936842,0.936404,0.935965,0.937281,0.937281,0.938596,0.938158,0.939912,0.939912,0.939912,0.940789,0.940789,0.939912,0.940789,0.942544,0.942544,0.942982,0.943421,0.944298,0.944737,0.944737,0.945175,0.946053,0.946491,0.94693,0.947368],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "name: 'training',\n",
       "},\n",
       "{\n",
       "x: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108],\n",
       "y: [0.744115,0.744115,0.744115,0.762538,0.802456,0.843398,0.847492,0.847492,0.846469,0.846469,0.843398,0.846469,0.848516,0.850563,0.847492,0.848516,0.849539,0.849539,0.850563,0.850563,0.850563,0.850563,0.85261,0.853634,0.853634,0.85261,0.85261,0.85261,0.854657,0.854657,0.854657,0.855681,0.855681,0.853634,0.855681,0.855681,0.856704,0.856704,0.858751,0.857728,0.857728,0.860798,0.859775,0.858751,0.858751,0.857728,0.856704,0.859775,0.859775,0.858751,0.860798,0.860798,0.862845,0.861822,0.861822,0.861822,0.859775,0.858751,0.859775,0.857728,0.858751,0.858751,0.857728,0.858751,0.858751,0.856704,0.857728,0.858751,0.858751,0.860798,0.859775,0.859775,0.859775,0.856704,0.859775,0.859775,0.860798,0.860798,0.861822,0.862845,0.860798,0.860798,0.861822,0.860798,0.857728,0.856704,0.856704,0.856704,0.857728,0.857728,0.855681,0.856704,0.856704,0.857728,0.858751,0.858751,0.861822,0.862845,0.863869,0.863869,0.864893,0.865916,0.867963,0.865916,0.864893,0.863869,0.864893,0.864893],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "name: 'validation',\n",
       "},\n",
       "],\n",
       "    {\n",
       "      width: 600,\n",
       "      height: 400,\n",
       "      title: '',\n",
       "      showlegend: true,\n",
       "      xaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'iteration',\n",
       "        },\n",
       "      font: {\n",
       "        size: 10,\n",
       "        },\n",
       "      yaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'accuracy',\n",
       "        },\n",
       "      margin: {\n",
       "        l: 50,\n",
       "        r: 50,\n",
       "        b: 50,\n",
       "        t: 50,\n",
       "      },\n",
       "    },\n",
       "    {\n",
       "      modeBarButtonsToRemove: ['sendDataToCloud'],\n",
       "      displaylogo: false,displayModeBar: false,\n",
       "    }\n",
       "  );\n",
       "</script>\n",
       "</div></div></div><div id=\"5de0-c876-a9e4-7936_body_variable_importance\" class=\"tab_content\"><p><a target=\"_blank\" href=\"https://ydf.readthedocs.io/en/latest/cli_user_manual#variable-importances\">Variable importances</a> measure the importance of an input feature for a model.</p><div id=\"5de0-c876-a9e4-7936_vi\" class=\"variable_importance\"><select onchange=\"ydfShowVariableImportance('5de0-c876-a9e4-7936_vi')\"><option value=\"INV_MEAN_MIN_DEPTH\">INV_MEAN_MIN_DEPTH</option><option value=\"NUM_AS_ROOT\">NUM_AS_ROOT</option><option value=\"NUM_NODES\">NUM_NODES</option><option value=\"SUM_SCORE\">SUM_SCORE</option></select><div id=\"5de0-c876-a9e4-7936_vi_body_INV_MEAN_MIN_DEPTH\" class=\"content selected\"><pre class=\"ydf_pre\">    1.   &quot;relationship&quot;  0.278801 ################\n",
       "    2.   &quot;capital_gain&quot;  0.260187 #############\n",
       "    3.     &quot;occupation&quot;  0.228313 ########\n",
       "    4.      &quot;education&quot;  0.224940 #######\n",
       "    5.            &quot;age&quot;  0.217297 ######\n",
       "    6. &quot;hours_per_week&quot;  0.212136 #####\n",
       "    7.         &quot;fnlwgt&quot;  0.199807 ###\n",
       "    8.   &quot;capital_loss&quot;  0.199368 ###\n",
       "    9.      &quot;workclass&quot;  0.197884 ###\n",
       "   10. &quot;marital_status&quot;  0.190656 ##\n",
       "   11.  &quot;education_num&quot;  0.188540 #\n",
       "   12. &quot;native_country&quot;  0.183821 \n",
       "   13.           &quot;race&quot;  0.182820 \n",
       "   14.            &quot;sex&quot;  0.177710 \n",
       "</pre></div><div id=\"5de0-c876-a9e4-7936_vi_body_NUM_AS_ROOT\" class=\"content\"><pre class=\"ydf_pre\">    1.   &quot;relationship&quot; 29.000000 ################\n",
       "    2.   &quot;capital_gain&quot; 20.000000 ##########\n",
       "    3. &quot;hours_per_week&quot;  7.000000 ###\n",
       "    4.            &quot;age&quot;  6.000000 ##\n",
       "    5.   &quot;capital_loss&quot;  6.000000 ##\n",
       "    6. &quot;marital_status&quot;  3.000000 #\n",
       "    7.      &quot;workclass&quot;  2.000000 \n",
       "    8.         &quot;fnlwgt&quot;  2.000000 \n",
       "    9.           &quot;race&quot;  2.000000 \n",
       "   10. &quot;native_country&quot;  1.000000 \n",
       "</pre></div><div id=\"5de0-c876-a9e4-7936_vi_body_NUM_NODES\" class=\"content\"><pre class=\"ydf_pre\">    1.     &quot;occupation&quot; 281.000000 ################\n",
       "    2.      &quot;education&quot; 223.000000 ############\n",
       "    3.         &quot;fnlwgt&quot; 220.000000 ############\n",
       "    4.            &quot;age&quot; 187.000000 ##########\n",
       "    5.   &quot;capital_gain&quot; 148.000000 ########\n",
       "    6. &quot;hours_per_week&quot; 133.000000 #######\n",
       "    7.   &quot;relationship&quot; 113.000000 ######\n",
       "    8.      &quot;workclass&quot; 93.000000 ####\n",
       "    9. &quot;marital_status&quot; 87.000000 ####\n",
       "   10.   &quot;capital_loss&quot; 74.000000 ###\n",
       "   11.  &quot;education_num&quot; 41.000000 #\n",
       "   12. &quot;native_country&quot; 32.000000 #\n",
       "   13.            &quot;sex&quot; 18.000000 \n",
       "   14.           &quot;race&quot; 12.000000 \n",
       "</pre></div><div id=\"5de0-c876-a9e4-7936_vi_body_SUM_SCORE\" class=\"content\"><pre class=\"ydf_pre\">    1.   &quot;relationship&quot; 473.506931 ################\n",
       "    2.   &quot;capital_gain&quot; 203.793310 ######\n",
       "    3.      &quot;education&quot; 178.370454 #####\n",
       "    4.  &quot;education_num&quot; 133.982814 ####\n",
       "    5.     &quot;occupation&quot; 108.582365 ###\n",
       "    6.            &quot;age&quot; 89.963566 ##\n",
       "    7.         &quot;fnlwgt&quot; 77.287484 ##\n",
       "    8. &quot;hours_per_week&quot; 62.848679 ##\n",
       "    9.   &quot;capital_loss&quot; 59.407506 #\n",
       "   10.      &quot;workclass&quot; 36.896641 #\n",
       "   11. &quot;marital_status&quot; 22.519862 \n",
       "   12. &quot;native_country&quot; 12.217495 \n",
       "   13.           &quot;race&quot;  3.595908 \n",
       "   14.            &quot;sex&quot;  3.356631 \n",
       "</pre></div></div><p>Those variable importances are computed during training. More, and possibly more informative, variable importances are available when analyzing a model on a test dataset.</p></div><div id=\"5de0-c876-a9e4-7936_body_structure\" class=\"tab_content\"><b>Num trees</b> : 78<br><p>Only printing the first tree.</p><pre class=\"ydf_pre\">Tree #0:\n",
       "    &quot;relationship&quot; is in [BITMAP] {&lt;OOD&gt;, Husband, Wife} [s:0.0382383 n:2280 np:1042 miss:1] ; pred:3.43208e-10\n",
       "        ├─(pos)─ &quot;education&quot; is in [BITMAP] {Bachelors, Masters, Prof-school, Doctorate} [s:0.0403089 n:1042 np:302 miss:0] ; pred:0.116594\n",
       "        |        ├─(pos)─ &quot;age&quot;&gt;=28.5 [s:0.00988429 n:302 np:287 miss:1] ; pred:0.288509\n",
       "        |        |        ├─(pos)─ &quot;occupation&quot; is in [BITMAP] {Exec-managerial, Prof-specialty, Sales, Other-service, Tech-support} [s:0.00590419 n:287 np:247 miss:0] ; pred:0.300942\n",
       "        |        |        |        ├─(pos)─ &quot;hours_per_week&quot;&gt;=41 [s:0.00534521 n:247 np:118 miss:0] ; pred:0.317856\n",
       "        |        |        |        |        ├─(pos)─ pred:0.359672\n",
       "        |        |        |        |        └─(neg)─ pred:0.279607\n",
       "        |        |        |        └─(neg)─ &quot;fnlwgt&quot;&gt;=281926 [s:0.0228571 n:40 np:5 miss:0] ; pred:0.196494\n",
       "        |        |        |                 ├─(pos)─ pred:-0.0223125\n",
       "        |        |        |                 └─(neg)─ pred:0.227752\n",
       "        |        |        └─(neg)─ &quot;occupation&quot; is in [BITMAP] {&lt;OOD&gt;, Prof-specialty, Sales, Adm-clerical, Other-service, Machine-op-inspct, Transport-moving, Handlers-cleaners, Farming-fishing, Tech-support, ...[2 left]} [s:0.031746 n:15 np:8 miss:0] ; pred:0.050623\n",
       "        |        |                 ├─(pos)─ pred:0.141792\n",
       "        |        |                 └─(neg)─ pred:-0.0535706\n",
       "        |        └─(neg)─ &quot;capital_gain&quot;&gt;=5095.5 [s:0.0186913 n:740 np:32 miss:0] ; pred:0.0464341\n",
       "        |                 ├─(pos)─ &quot;fnlwgt&quot;&gt;=112632 [s:0.00527344 n:32 np:27 miss:1] ; pred:0.398206\n",
       "        |                 |        ├─(pos)─ pred:0.415301\n",
       "        |                 |        └─(neg)─ pred:0.305897\n",
       "        |                 └─(neg)─ &quot;capital_loss&quot;&gt;=1791.5 [s:0.00843925 n:708 np:30 miss:0] ; pred:0.0305348\n",
       "        |                          ├─(pos)─ &quot;capital_loss&quot;&gt;=1989.5 [s:0.0938889 n:30 np:10 miss:0] ; pred:0.26943\n",
       "        |                          |        ├─(pos)─ pred:0.0323891\n",
       "        |                          |        └─(neg)─ pred:0.38795\n",
       "        |                          └─(neg)─ &quot;education&quot; is in [BITMAP] {&lt;OOD&gt;, HS-grad, Some-college, Bachelors, Masters, Assoc-voc, Assoc-acdm, Prof-school, 12th, Doctorate} [s:0.00686782 n:678 np:577 miss:1] ; pred:0.0199643\n",
       "        |                                   ├─(pos)─ pred:0.0389306\n",
       "        |                                   └─(neg)─ pred:-0.0883878\n",
       "        └─(neg)─ &quot;capital_gain&quot;&gt;=4718.5 [s:0.0153776 n:1238 np:29 miss:0] ; pred:-0.0981348\n",
       "                 ├─(pos)─ &quot;occupation&quot; is in [BITMAP] {Craft-repair, Exec-managerial, Prof-specialty, Sales, Transport-moving} [s:0.0444808 n:29 np:24 miss:1] ; pred:0.33985\n",
       "                 |        ├─(pos)─ &quot;hours_per_week&quot;&gt;=53.5 [s:0.00659722 n:24 np:5 miss:0] ; pred:0.392508\n",
       "                 |        |        ├─(pos)─ pred:0.305897\n",
       "                 |        |        └─(neg)─ pred:0.415301\n",
       "                 |        └─(neg)─ pred:0.0870908\n",
       "                 └─(neg)─ &quot;education_num&quot;&gt;=12.5 [s:0.00245124 n:1209 np:240 miss:0] ; pred:-0.108641\n",
       "                          ├─(pos)─ &quot;age&quot;&gt;=30.5 [s:0.00913471 n:240 np:147 miss:1] ; pred:-0.0542218\n",
       "                          |        ├─(pos)─ &quot;occupation&quot; is in [BITMAP] {&lt;OOD&gt;, Exec-managerial, Prof-specialty, Adm-clerical, Machine-op-inspct, Protective-serv, Priv-house-serv} [s:0.00900639 n:147 np:110 miss:0] ; pred:-0.0126374\n",
       "                          |        |        ├─(pos)─ pred:0.0174705\n",
       "                          |        |        └─(neg)─ pred:-0.102147\n",
       "                          |        └─(neg)─ &quot;fnlwgt&quot;&gt;=276854 [s:0.00222569 n:93 np:16 miss:0] ; pred:-0.119952\n",
       "                          |                 ├─(pos)─ pred:-0.0633387\n",
       "                          |                 └─(neg)─ pred:-0.131716\n",
       "                          └─(neg)─ &quot;hours_per_week&quot;&gt;=42.5 [s:0.000376868 n:969 np:166 miss:0] ; pred:-0.122119\n",
       "                                   ├─(pos)─ &quot;occupation&quot; is in [BITMAP] {&lt;OOD&gt;, Prof-specialty, Sales, Transport-moving} [s:0.00418084 n:166 np:40 miss:0] ; pred:-0.098763\n",
       "                                   |        ├─(pos)─ pred:-0.0359879\n",
       "                                   |        └─(neg)─ pred:-0.118692\n",
       "                                   └─(neg)─ &quot;occupation&quot; is in [BITMAP] {&lt;OOD&gt;, Prof-specialty} [s:9.2485e-05 n:803 np:39 miss:0] ; pred:-0.126947\n",
       "                                            ├─(pos)─ pred:-0.103664\n",
       "                                            └─(neg)─ pred:-0.128136\n",
       "</pre></div></div></div>"
      ],
      "text/plain": [
       "<ydf.utils.html.HtmlNotebookDisplay at 0x7fc9c3924770>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00404093, 0.35932407, 0.8662793 , ..., 0.01358805, 0.04585141,\n",
       "       0.00885384], shape=(9769,), dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying model\n",
    "\n",
    "The model can now be deployed. YDF offers several options: C++, FastAPI, TensorFlow Serving, etc.\n",
    "See the \"Deploying a model\" section on the left for more details.\n",
    "\n",
    "To give an example, let's deploy the model with FastAPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_docker(\"/tmp/docker_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "-rw-r----- 1 gbm primarygroup  288 Mar  6 14:22 deploy_in_google_cloud.sh\n",
      "-rw-r----- 1 gbm primarygroup  211 Mar  6 14:22 Dockerfile\n",
      "-rw-r----- 1 gbm primarygroup 1313 Mar  6 14:22 main.py\n",
      "drwxr-x--- 2 gbm primarygroup  140 Mar  6 14:22 model\n",
      "-rw-r----- 1 gbm primarygroup  360 Mar  6 14:22 readme.txt\n",
      "-rw-r----- 1 gbm primarygroup   26 Mar  6 14:22 requirements.txt\n",
      "-rw-r----- 1 gbm primarygroup  485 Mar  6 14:22 test_locally.sh\n"
     ]
    }
   ],
   "source": [
    "!ls -l /tmp/docker_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model in Google Cloud Run.\n",
    "\n",
    "The results will be available in the [Google Cloud Run console](https://pantheon.corp.google.com/run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deploying from source requires an Artifact Registry Docker repository to store \n",
      "repository named [cloud-run-source-deploy] in region \n",
      "[us-east1] will be created.\n",
      "\n",
      "ntinue (Y/n)?  co\n",
      "Allow unauthenticated invocations to [ydf-predict] (y/N)?  \n",
      "Building using Dockerfile and deploying container to Cloud Run service [\u001b[1mydf-predict\u001b[m] in project [\u001b[1mcustom-oasis-452410-c2\u001b[m] region [\u001b[1mus-east1\u001b[m]\n",
      "Building and deploying new service...\n",
      "Creating Container Repository................................................................................................................done\n",
      "Uploading sources..................Creating temporary archive of 11 file(s) totalling 228.1 KiB before compression.\n",
      "Uploading zipfile of [/tmp/docker_model] to [gs://run-sources-custom-oasis-452410-c2-us-east1/services/ydf-predict/1741267781.721195-c0f972bb00c345d2ae780b88d7a4f65d.zip]\n",
      "......done\n",
      "Building Container.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done\n",
      "Creating Revision........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done\n",
      "Routing traffic.....done\n",
      "Done.\n",
      "Service [\u001b[1mydf-predict\u001b[m] revision [\u001b[1mydf-predict-00001-8dc\u001b[m] has been deployed and is serving \u001b[1m100\u001b[m percent of traffic.\n",
      "[mrvice URL: \u001b[1mhttps://ydf-predict-282665763673.us-east1.run.app\u001b\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Enable Google Cloud Run\n",
    "gcloud services enable run.googleapis.com\n",
    "# Deploy the model as a service\n",
    "gcloud run deploy ydf-predict --source /tmp/docker_model --region=us-east1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
